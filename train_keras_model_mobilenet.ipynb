{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "train_keras_model_mobilenet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q501AkZ6uBv"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZmp7J7BmqWv"
      },
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQyDsJAotT_L"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import GlobalAveragePooling2D, Dropout, Dense, Activation, BatchNormalization, Conv2D, MaxPool2D, Flatten, MaxPooling2D\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from keras.optimizers import SGD, Adam\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTbF99pVECvT"
      },
      "source": [
        "__author__ = \"Arthur Fortes da Costas\"\n",
        "__copyright__ = \"Copyright 2021\"\n",
        "__credits__ = [\"Arthur Fortes\"]\n",
        "__license__ = \"MIT\"\n",
        "__version__ = \"1.0\"\n",
        "__maintainer__ = \"Arthur Fortes\"\n",
        "__email__ = \"fortes.arthur@gmail.com@gmail.com\"\n",
        "__status__ = \"Dev\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXM1NQhp6or5"
      },
      "source": [
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKvKUZJmtT_S"
      },
      "source": [
        "### Params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBRNVHSetT_T"
      },
      "source": [
        "MODEL_SAVE = 'service_type_model.h5'\n",
        "FAST_RUN = False\n",
        "IMAGE_WIDTH = 300\n",
        "IMAGE_HEIGHT = 300\n",
        "IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS = 1\n",
        "IMG_DIR = 'imagens/'\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 4"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4amawXF7rj4"
      },
      "source": [
        "## Start by connecting gdrive into the google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9fpq0_e7wC-"
      },
      "source": [
        "! cp \"/content/gdrive/My Drive/Projects/MaskDetection/dataset/mask_dataset_images.zip\" ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zzsyRFY75aS"
      },
      "source": [
        "! unzip mask_dataset_images.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z97T2J106or7"
      },
      "source": [
        "### Create dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9SiDBAy6or8"
      },
      "source": [
        "dataset = []\n",
        "\n",
        "for fold in os.listdir(IMG_DIR):\n",
        "    for filename in os.listdir(f'{IMG_DIR}/{fold}'):\n",
        "        dataset.append((f'{fold}/{filename}', fold))\n",
        "\n",
        "df = pd.DataFrame(dataset, columns=['filename', 'category'])\n",
        "df_train, df_test = train_test_split(df, random_state=42, stratify=df.category, test_size=.2)\n",
        "df_train['set'] = 'train'\n",
        "df_test['set'] = 'test'\n",
        "df = df_train.append(df_test)\n",
        "df.to_csv('dataset.csv', index=False)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uPQPPjrtT_V"
      },
      "source": [
        "### Read and prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQb0GLmotT_W"
      },
      "source": [
        "df = pd.read_csv('dataset.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Mf1AYwCtT_Z"
      },
      "source": [
        "train_df = df[df.set == 'train'].reset_index(drop=True)\n",
        "validate_df = df[df.set == 'test'].reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muIJceKvtT_e"
      },
      "source": [
        "### Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfEElkTbtT_f"
      },
      "source": [
        "base_model = MobileNet(\n",
        "    weights= None, \n",
        "    include_top=False, \n",
        "    input_shape= (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)\n",
        ")\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256,activation='relu')(x) \n",
        "x = Dropout(0.2)(x)\n",
        "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "opt = Adam(lr=0.000125)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrJNPB8GtT_i"
      },
      "source": [
        "### Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7ZwczFitT_i"
      },
      "source": [
        "callbacks_list = [\n",
        "    ModelCheckpoint('/content/gdrive/My Drive/Projects/MaskDetection/weights/service_weights.h5', \n",
        "                    monitor='val_accuracy', verbose=1, save_best_only=True, mode='max'),\n",
        "    EarlyStopping(monitor='val_accuracy', patience=5),\n",
        "    ReduceLROnPlateau(monitor='val_accuracy', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JCWz7qxtT_k"
      },
      "source": [
        "### Generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUn-S1hPtT_l"
      },
      "source": [
        "def add_noise(img):\n",
        "    '''Add random noise to an image'''\n",
        "    VARIABILITY = 8\n",
        "    deviation = VARIABILITY*random.random()\n",
        "    noise = np.random.normal(0, deviation, img.shape)\n",
        "    img += noise\n",
        "    np.clip(img, 0., 255.)\n",
        "    return img\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    brightness_range=[0.2, 1.6],\n",
        "    rescale=1. / 255,\n",
        "    rotation_range=0, \n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1, \n",
        "    shear_range=0.2, \n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True, \n",
        "    fill_mode=\"nearest\",\n",
        "    preprocessing_function=add_noise,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTQ13gs3tT_n"
      },
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df, \n",
        "    IMG_DIR, \n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    color_mode = 'grayscale',\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY89S7qQtT_q"
      },
      "source": [
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_dataframe(\n",
        "    validate_df, \n",
        "    IMG_DIR,\n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    color_mode = 'grayscale',\n",
        "    class_mode='categorical',\n",
        "    shuffle=False,\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmJizDNhtT_t"
      },
      "source": [
        "### Fit model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J20h0IEctT_t"
      },
      "source": [
        "total_train = train_df.shape[0]\n",
        "total_validate = validate_df.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q7G1d7LQxQ_"
      },
      "source": [
        "model.load_weights('/content/gdrive/My Drive/Projects/MaskDetection/weights/service_weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjCL7KT0tT_y"
      },
      "source": [
        "epochs=50 if FAST_RUN else 50\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator, \n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=total_validate//BATCH_SIZE,\n",
        "    steps_per_epoch=total_train//BATCH_SIZE,\n",
        "    callbacks=callbacks_list\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxvLNWfQ8zJu"
      },
      "source": [
        "nb_samples = validate_df.shape[0]\n",
        "predict = model.predict_generator(validation_generator, steps=np.ceil(nb_samples/BATCH_SIZE))\n",
        "validate_df['pred'] = np.argmax(predict, axis=-1)\n",
        "label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n",
        "validate_df['pred'] = validate_df['pred'].replace(label_map)\n",
        "label_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vztbbePhOpG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a-lmHQ58zye"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(validate_df.category, validate_df.pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LigvK7Kb8z1Q"
      },
      "source": [
        "print(confusion_matrix(validate_df.category, validate_df.pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h2zMSm28bBR"
      },
      "source": [
        "model.save('model_colab.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AH7ShAs6osI"
      },
      "source": [
        "model.save('/content/gdrive/My Drive/Projects/MaskDetection/model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah4seexbZU3O"
      },
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def load_dataframe():\n",
        "    '''\n",
        "    Carrega um dataframe Pandas com as imagens para o treinamento do modelo\n",
        "    '''\n",
        "    data_info = {\n",
        "        \"filename\": [],\n",
        "        \"label\": [],\n",
        "        \"target\": [],\n",
        "        \"image\": [],\n",
        "    }\n",
        "\n",
        "    with_mask = os.listdir(\"imagens/maskon\")\n",
        "    without_mask = os.listdir(\"imagens/maskoff\")\n",
        "    mask_chin = os.listdir(\"imagens/maskchin\")\n",
        "    mask_mouth = os.listdir(\"imagens/maskmouth\")\n",
        "\n",
        "    for filename in with_mask:\n",
        "        data_info[\"filename\"].append(f\"imagens/maskchin/{filename}\")\n",
        "        data_info[\"label\"].append(f\"Mask only in the chin\")\n",
        "        data_info[\"target\"].append(1)\n",
        "        img = cv.imread(f\"imagens/maskchin/{filename}\")\n",
        "        img = cv.cvtColor(img, cv.COLOR_BGR2GRAY).flatten()\n",
        "        data_info[\"image\"].append(img)\n",
        "\n",
        "    for filename in with_mask:\n",
        "        data_info[\"filename\"].append(f\"imagens/maskmouth/{filename}\")\n",
        "        data_info[\"label\"].append(f\"Mask below the nose\")\n",
        "        data_info[\"target\"].append(1)\n",
        "        img = cv.cvtColor(cv.imread(f\"imagens/maskmouth/{filename}\"), cv.COLOR_BGR2GRAY).flatten()\n",
        "        data_info[\"image\"].append(img)\n",
        "\n",
        "    for filename in without_mask:\n",
        "        data_info[\"filename\"].append(f\"imagens/maskoff/{filename}\")\n",
        "        data_info[\"label\"].append(f\"Without Mask\")\n",
        "        data_info[\"target\"].append(2)\n",
        "        img = cv.cvtColor(cv.imread(f\"imagens/maskoff/{filename}\"), cv.COLOR_BGR2GRAY).flatten()\n",
        "        data_info[\"image\"].append(img)\n",
        "\n",
        "    for filename in with_mask:\n",
        "        data_info[\"filename\"].append(f\"imagens/maskon/{filename}\")\n",
        "        data_info[\"label\"].append(f\"With Mask\")\n",
        "        data_info[\"target\"].append(3)\n",
        "        img = cv.cvtColor(cv.imread(f\"imagens/maskon/{filename}\"), cv.COLOR_BGR2GRAY).flatten()\n",
        "        data_info[\"image\"].append(img)\n",
        "\n",
        "        \n",
        "    dataframe = pd.DataFrame(dados)\n",
        "\n",
        "    return dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUur_P8nZzCU"
      },
      "source": [
        "def train_test(dataframe):\n",
        "    '''\n",
        "    Divide o dataframe em conjunto de treino e teste\n",
        "    '''\n",
        "    X = list(dataframe[\"image\"])\n",
        "    y = list(dataframe[\"target\"])\n",
        "\n",
        "    return train_test_split(X, y, train_size=0.40, random_state=13)\n",
        "\n",
        "\n",
        "def pca_model(X_train):\n",
        "    '''\n",
        "    PCA para extração de features das imagens\n",
        "    '''\n",
        "    pca = PCA(n_components=50)\n",
        "    pca.fit(X_train)\n",
        "    \n",
        "    return pca"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3cXzdLeZ4Bi"
      },
      "source": [
        "dataframe = load_dataframe() #Carregando dataframe com as imagens para treinamento\n",
        "\n",
        "X_train, X_test, y_train, y_test = functions.train_test(dataframe) #Dividindo conjuntos de treino e teste\n",
        "pca = functions.pca_model(X_train) #Modelo PCA para extração de features da imagem"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}